--- a/ferum_customs/openai_utils.py
+++ b/ferum_customs/openai_utils.py
@@ -1,17 +1,31 @@
-1. **API Key Exposure**: Ensure that the API key is not logged or exposed in any way. Consider using environment variables or a secure vault for sensitive information.
-   
-2. **Error Handling**: The code does not handle potential exceptions from the `openai.ChatCompletion.create` call. Wrap it in a try-except block to catch and handle exceptions gracefully.
+import os
+from typing import Optional
+import openai
 
-3. **Hardcoded Model Name**: The model name "gpt-4" is hardcoded. Consider passing it as a parameter to the function or using a configuration setting to allow for flexibility.
+def generate_response(prompt: str, model: str = "gpt-4", max_tokens: int = 100) -> Optional[str]:
+    """
+    Generate a response from the OpenAI API.
 
-4. **Stop Sequences**: The stop sequences should be carefully chosen based on the expected output. Ensure that they do not inadvertently cut off valid responses.
+    Parameters:
+    - prompt (str): The input prompt for the model.
+    - model (str): The model to use for generating the response. Default is "gpt-4".
+    - max_tokens (int): The maximum number of tokens to generate. Default is 100.
 
-5. **Type Hinting**: The return type of the function is specified as `str`, but it would be better to use `Optional[str]` if there's a possibility of returning `None` in case of an error.
+    Returns:
+    - Optional[str]: The generated response or None if an error occurs.
+    """
+    # Sanitize input prompt to prevent injection attacks
+    sanitized_prompt = prompt.strip()
 
-6. **Magic Numbers**: The `max_tokens` value is hardcoded. Consider making it a configurable parameter.
-
-7. **Docstring**: The docstring could be more descriptive, including details about the parameters and return values.
-
-8. **Security**: Ensure that the input `prompt` is sanitized to prevent injection attacks or unintended behavior.
-
-9. **Unused Import**: The import statement for `from __future__ import annotations` is unnecessary unless type hints are being used in a forward reference context.
+    try:
+        response = openai.ChatCompletion.create(
+            model=model,
+            messages=[{"role": "user", "content": sanitized_prompt}],
+            max_tokens=max_tokens,
+            stop=None  # Define stop sequences as needed
+        )
+        return response.choices[0].message['content']
+    except Exception as e:
+        # Handle exceptions gracefully
+        print(f"An error occurred: {e}")
+        return None