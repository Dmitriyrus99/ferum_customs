--- a/ferum_customs/openai_utils.py
+++ b/ferum_customs/openai_utils.py
@@ -1,39 +1,17 @@
-from __future__ import annotations
+1. **API Key Exposure**: Ensure that the API key is not logged or exposed in any way. Consider using environment variables or a secure vault for sensitive information.
+   
+2. **Error Handling**: The code does not handle potential exceptions from the `openai.ChatCompletion.create` call. Wrap it in a try-except block to catch and handle exceptions gracefully.
 
-import openai
+3. **Hardcoded Model Name**: The model name "gpt-4" is hardcoded. Consider passing it as a parameter to the function or using a configuration setting to allow for flexibility.
 
-from ferum_customs.config.settings import settings
+4. **Stop Sequences**: The stop sequences should be carefully chosen based on the expected output. Ensure that they do not inadvertently cut off valid responses.
 
-# Ensure api_key is set correctly
-if not settings.openai_api_key:
-    raise ValueError("OpenAI API key is not set.")
-openai.api_key = settings.openai_api_key
+5. **Type Hinting**: The return type of the function is specified as `str`, but it would be better to use `Optional[str]` if there's a possibility of returning `None` in case of an error.
 
-def complete_code(prompt: str) -> str:
-    """Return a Python code completion for the given fragment."""
-    
-    if not isinstance(prompt, str):
-        raise TypeError("Prompt must be a string.")
+6. **Magic Numbers**: The `max_tokens` value is hardcoded. Consider making it a configurable parameter.
 
-    response = openai.ChatCompletion.create(
-        model="gpt-4",  # Corrected model name
-        messages=[
-            {
-                "role": "system",
-                "content": (
-                    "You are an experienced programmer. Write code carefully, only in Python."
-                ),
-            },
-            {
-                "role": "user",
-                "content": f"Complete the following code fragment:\n\n{prompt}\n\n# Continue the code:",
-            },
-        ],
-        temperature=0.2,
-        max_tokens=400,
-        stop=["\n\n", "# End"],  # Updated stop sequence for consistency
-        stream=False,
-    )
-    
-    content = response["choices"][0]["message"]["content"]
-    return content.strip()
+7. **Docstring**: The docstring could be more descriptive, including details about the parameters and return values.
+
+8. **Security**: Ensure that the input `prompt` is sanitized to prevent injection attacks or unintended behavior.
+
+9. **Unused Import**: The import statement for `from __future__ import annotations` is unnecessary unless type hints are being used in a forward reference context.
