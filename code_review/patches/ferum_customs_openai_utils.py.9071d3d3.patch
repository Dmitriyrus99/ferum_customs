--- a/ferum_customs/openai_utils.py
+++ b/ferum_customs/openai_utils.py
@@ -1,6 +1,11 @@
 import os
 import openai
+import logging
 from typing import Optional
+
+# Configure logging
+logging.basicConfig(level=logging.INFO)
+logger = logging.getLogger(__name__)
 
 def get_chat_completion(prompt: str, model: Optional[str] = "gpt-4", max_tokens: Optional[int] = 150) -> Optional[str]:
     """
@@ -21,6 +26,11 @@
 
     openai.api_key = api_key
 
+    # Validate model
+    allowed_models = ["gpt-3.5-turbo", "gpt-4"]
+    if model not in allowed_models:
+        raise ValueError(f"Model '{model}' is not allowed. Choose from {allowed_models}.")
+
     try:
         sanitized_prompt = sanitize_input(prompt)
         response = openai.ChatCompletion.create(
@@ -31,11 +41,19 @@
         )
         return response.choices[0].message['content'].strip()
     except openai.error.OpenAIError as e:
-        # Log the error or handle it as needed
-        print(f"An error occurred: {e}")
+        logger.error(f"An error occurred: {e}")
         return None
 
 # Ensure input prompt is sanitized
 def sanitize_input(prompt: str) -> str:
+    """
+    Sanitizes the input prompt to prevent potential security issues.
+
+    Parameters:
+    - prompt (str): The input prompt to sanitize.
+
+    Returns:
+    - str: The sanitized prompt.
+    """
     # Implement sanitization logic as needed
-    return prompt
+    return prompt.strip()  # Example of basic sanitization
