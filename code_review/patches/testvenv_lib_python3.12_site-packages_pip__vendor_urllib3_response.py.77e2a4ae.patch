--- a/testvenv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py
+++ b/testvenv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py
@@ -88,10 +88,8 @@
                 ret += self._obj.decompress(data)
             except zlib.error:
                 previous_state = self._state
-                # Ignore data after the first error
                 self._state = GzipDecoderState.SWALLOW_DATA
                 if previous_state == GzipDecoderState.OTHER_MEMBERS:
-                    # Allow trailing garbage acceptable in other gzip clients
                     return bytes(ret)
                 raise
             data = self._obj.unused_data
@@ -104,9 +102,6 @@
 if brotli is not None:
 
     class BrotliDecoder(object):
-        # Supports both 'brotlipy' and 'Brotli' packages
-        # since they share an import name. The top branches
-        # are for 'brotlipy' and bottom branches for 'Brotli'
         def __init__(self):
             self._obj = brotli.Decompressor()
             if hasattr(self._obj, "decompress"):
@@ -121,14 +116,6 @@
 
 
 class MultiDecoder(object):
-    """
-    From RFC7231:
-        If one or more encodings have been applied to a representation, the
-        sender that applied the encodings MUST generate a Content-Encoding
-        header field that lists the content codings in the order in which
-        they were applied.
-    """
-
     def __init__(self, modes):
         self._decoders = [_get_decoder(m.strip()) for m in modes.split(",")]
 
@@ -155,38 +142,6 @@
 
 
 class HTTPResponse(io.IOBase):
-    """
-    HTTP Response container.
-
-    Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
-    loaded and decoded on-demand when the ``data`` property is accessed.  This
-    class is also compatible with the Python standard library's :mod:`io`
-    module, and can hence be treated as a readable object in the context of that
-    framework.
-
-    Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:
-
-    :param preload_content:
-        If True, the response's body will be preloaded during construction.
-
-    :param decode_content:
-        If True, will attempt to decode the body based on the
-        'content-encoding' header.
-
-    :param original_response:
-        When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
-        object, it's convenient to include the original for debug purposes. It's
-        otherwise unused.
-
-    :param retries:
-        The retries contains the last :class:`~urllib3.util.retry.Retry` that
-        was used during the request.
-
-    :param enforce_content_length:
-        Enforce content length checking. Body returned by server must match
-        value of Content-Length header, if present. Otherwise, raise error.
-    """
-
     CONTENT_DECODERS = ["gzip", "deflate"]
     if brotli is not None:
         CONTENT_DECODERS += ["br"]
@@ -243,30 +198,19 @@
         if hasattr(body, "read"):
             self._fp = body
 
-        # Are we using the chunked-style of transfer encoding?
         self.chunked = False
         self.chunk_left = None
         tr_enc = self.headers.get("transfer-encoding", "").lower()
-        # Don't incur the penalty of creating a list and then discarding it
         encodings = (enc.strip() for enc in tr_enc.split(","))
         if "chunked" in encodings:
             self.chunked = True
 
-        # Determine length of response
         self.length_remaining = self._init_length(request_method)
 
-        # If requested, preload the body.
         if preload_content and not self._body:
             self._body = self.read(decode_content=decode_content)
 
     def get_redirect_location(self):
-        """
-        Should we redirect and where to?
-
-        :returns: Truthy redirect location string if we got a redirect status
-            code and valid location. ``None`` if redirect status and no
-            location. ``False`` if not a redirect status code.
-        """
         if self.status in self.REDIRECT_STATUSES:
             return self.headers.get("location")
 
@@ -280,11 +224,6 @@
         self._connection = None
 
     def drain_conn(self):
-        """
-        Read and discard any remaining HTTP response data in the response connection.
-
-        Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.
-        """
         try:
             self.read()
         except (HTTPError, SocketError, BaseSSLError, HTTPException):
@@ -292,7 +231,6 @@
 
     @property
     def data(self):
-        # For backwards-compat with earlier urllib3 0.4 and earlier.
         if self._body:
             return self._body
 
@@ -307,24 +245,13 @@
         return is_fp_closed(self._fp)
 
     def tell(self):
-        """
-        Obtain the number of bytes pulled over the wire so far. May differ from
-        the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
-        if bytes are encoded on the wire (e.g, compressed).
-        """
         return self._fp_bytes_read
 
     def _init_length(self, request_method):
-        """
-        Set initial length value for Response content if available.
-        """
         length = self.headers.get("content-length")
 
         if length is not None:
             if self.chunked:
-                # This Response will fail with an IncompleteRead if it can't be
-                # received as chunked. This method falls back to attempt reading
-                # the response before raising an exception.
                 log.warning(
                     "Received response with both Content-Length and "
                     "Transfer-Encoding set. This is expressly forbidden "
@@ -335,11 +262,6 @@
                 return None
 
             try:
-                # RFC 7230 section 3.3.2 specifies multiple content lengths can
-                # be sent in a single Content-Length header
-                # (e.g. Content-Length: 42, 42). This line ensures the values
-                # are all valid ints and that as long as the `set` length is 1,
-                # all values are the same. Otherwise, the header is invalid.
                 lengths = set([int(val) for val in length.split(",")])
                 if len(lengths) > 1:
                     raise InvalidHeader(
@@ -353,25 +275,17 @@
                 if length < 0:
                     length = None
 
-        # Convert status to int for comparison
-        # In some cases, httplib returns a status of "_UNKNOWN"
         try:
             status = int(self.status)
         except ValueError:
             status = 0
 
-        # Check for responses that shouldn't include a body
         if status in (204, 304) or 100 <= status < 200 or request_method == "HEAD":
             length = 0
 
         return length
 
     def _init_decoder(self):
-        """
-        Set-up the _decoder attribute if necessary.
-        """
-        # Note: content-encoding value should be case-insensitive, per RFC 7230
-        # Section 3.2
         content_encoding = self.headers.get("content-encoding", "").lower()
         if self._decoder is None:
             if content_encoding in self.CONTENT_DECODERS:
@@ -390,9 +304,6 @@
         DECODER_ERROR_CLASSES += (brotli.error,)
 
     def _decode(self, data, decode_content, flush_decoder):
-        """
-        Decode the data passed in and potentially flush the decoder.
-        """
         if not decode_content:
             return data
 
@@ -412,10 +323,6 @@
         return data
 
     def _flush_decoder(self):
-        """
-        Flushes the decoder. Should only be called if the decoder is actually
-        being used.
-        """
         if self._decoder:
             buf = self._decoder.decompress(b"")
             return buf + self._decoder.flush()
@@ -424,13 +331,6 @@
 
     @contextmanager
     def _error_catcher(self):
-        """
-        Catch low-level python exceptions, instead re-raising urllib3
-        variants, so that low-level exceptions are not leaked in the
-        high-level api.
-
-        On exit, release the connection back to the pool.
-        """
         clean_exit = False
 
         try:
@@ -438,60 +338,30 @@
                 yield
 
             except SocketTimeout:
-                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
-                # there is yet no clean way to get at it from this context.
                 raise ReadTimeoutError(self._pool, None, "Read timed out.")
 
             except BaseSSLError as e:
-                # FIXME: Is there a better way to differentiate between SSLErrors?
                 if "read operation timed out" not in str(e):
-                    # SSL errors related to framing/MAC get wrapped and reraised here
                     raise SSLError(e)
 
                 raise ReadTimeoutError(self._pool, None, "Read timed out.")
 
             except (HTTPException, SocketError) as e:
-                # This includes IncompleteRead.
                 raise ProtocolError("Connection broken: %r" % e, e)
 
-            # If no exception is thrown, we should avoid cleaning up
-            # unnecessarily.
             clean_exit = True
         finally:
-            # If we didn't terminate cleanly, we need to throw away our
-            # connection.
             if not clean_exit:
-                # The response may not be closed but we're not going to use it
-                # anymore so close it now to ensure that the connection is
-                # released back to the pool.
                 if self._original_response:
                     self._original_response.close()
 
-                # Closing the response may not actually be sufficient to close
-                # everything, so if we have a hold of the connection close that
-                # too.
                 if self._connection:
                     self._connection.close()
 
-            # If we hold the original response but it's closed now, we should
-            # return the connection back to the pool.
             if self._original_response and self._original_response.isclosed():
                 self.release_conn()
 
     def _fp_read(self, amt):
-        """
-        Read a response with the thought that reading the number of bytes
-        larger than can fit in a 32-bit int at a time via SSL in some
-        known cases leads to an overflow error that has to be prevented
-        if `amt` or `self.length_remaining` indicate that a problem may
-        happen.
-
-        The known cases:
-          * 3.8 <= CPython < 3.9.7 because of a bug
-            https://github.com/urllib3/urllib3/issues/2513#issuecomment-1152559900.
-          * urllib3 injected with pyOpenSSL-backed SSL-support.
-          * CPython < 3.10 only when `amt` does not fit 32-bit int.
-        """
         assert self._fp
         c_int_max = 2**31 - 1
         if (
@@ -503,12 +373,6 @@
             and (util.IS_PYOPENSSL or sys.version_info < (3, 10))
         ):
             buffer = io.BytesIO()
-            # Besides `max_chunk_amt` being a maximum chunk size, it
-            # affects memory overhead of reading a response by this
-            # method in CPython.
-            # `c_int_max` equal to 2 GiB - 1 byte is the actual maximum
-            # chunk size that does not lead to an overflow error, but
-            # 256 MiB is a compromise.
             max_chunk_amt = 2**28
             while amt is None or amt != 0:
                 if amt is not None:
@@ -520,33 +384,12 @@
                 if not data:
                     break
                 buffer.write(data)
-                del data  # to reduce peak memory usage by `max_chunk_amt`.
+                del data
             return buffer.getvalue()
         else:
-            # StringIO doesn't like amt=None
             return self._fp.read(amt) if amt is not None else self._fp.read()
 
     def read(self, amt=None, decode_content=None, cache_content=False):
-        """
-        Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
-        parameters: ``decode_content`` and ``cache_content``.
-
-        :param amt:
-            How much of the content to read. If specified, caching is skipped
-            because it doesn't make sense to cache partial content as the full
-            response.
-
-        :param decode_content:
-            If True, will attempt to decode the body based on the
-            'content-encoding' header.
-
-        :param cache_content:
-            If True, will save the returned data such that the same result is
-            returned despite of the state of the underlying file object. This
-            is useful if you want the ``.data`` property to continue working
-            after having ``.read()`` the file object. (Overridden if ``amt`` is
-            set.)
-        """
         self._init_decoder()
         if decode_content is None:
             decode_content = self.decode_content
@@ -565,25 +408,13 @@
                 cache_content = False
                 if (
                     amt != 0 and not data
-                ):  # Platform-specific: Buggy versions of Python.
-                    # Close the connection when no data is returned
-                    #
-                    # This is redundant to what httplib/http.client _should_
-                    # already do.  However, versions of python released before
-                    # December 15, 2012 (http://bugs.python.org/issue16298) do
-                    # not properly close the connection in all cases. There is
-                    # no harm in redundantly calling close.
+                ):
                     self._fp.close()
                     flush_decoder = True
                     if self.enforce_content_length and self.length_remaining not in (
                         0,
                         None,
                     ):
-                        # This is an edge case that httplib failed to cover due
-                        # to concerns of backward compatibility. We're
-                        # addressing it here to make sure IncompleteRead is
-                        # raised during streaming, so all calls with incorrect
-                        # Content-Length are caught.
                         raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
 
         if data:
@@ -599,21 +430,6 @@
         return data
 
     def stream(self, amt=2**16, decode_content=None):
-        """
-        A generator wrapper for the read() method. A call will block until
-        ``amt`` bytes have been read from the connection or until the
-        connection is closed.
-
-        :param amt:
-            How much of the content to read. The generator will return up to
-            much data per iteration, but may return less. This is particularly
-            likely when using compressed data. However, the empty string will
-            never be returned.
-
-        :param decode_content:
-            If True, will attempt to decode the body based on the
-            'content-encoding' header.
-        """
         if self.chunked and self.supports_chunked_reads():
             for line in self.read_chunked(amt, decode_content=decode_content):
                 yield line
@@ -626,23 +442,14 @@
 
     @classmethod
     def from_httplib(ResponseCls, r, **response_kw):
-        """
-        Given an :class:`http.client.HTTPResponse` instance ``r``, return a
-        corresponding :class:`urllib3.response.HTTPResponse` object.
-
-        Remaining parameters are passed to the HTTPResponse constructor, along
-        with ``original_response=r``.
-        """
         headers = r.msg
 
         if not isinstance(headers, HTTPHeaderDict):
             if six.PY2:
-                # Python 2.7
                 headers = HTTPHeaderDict.from_httplib(headers)
             else:
                 headers = HTTPHeaderDict(headers.items())
 
-        # HTTPResponse objects in Python 3 don't have a .strict attribute
         strict = getattr(r, "strict", 0)
         resp = ResponseCls(
             body=r,
@@ -656,7 +463,6 @@
         )
         return resp
 
-    # Backwards-compatibility methods for http.client.HTTPResponse
     def getheaders(self):
         warnings.warn(
             "HTTPResponse.getheaders() is deprecated and will be removed "
@@ -675,11 +481,9 @@
         )
         return self.headers.get(name, default)
 
-    # Backwards compatibility for http.cookiejar
     def info(self):
         return self.headers
 
-    # Overrides from io.IOBase
     def close(self):
         if not self.closed:
             self._fp.close()
@@ -723,11 +527,9 @@
             return self._fp.flush()
 
     def readable(self):
-        # This method is required for `io` module compatibility.
         return True
 
     def readinto(self, b):
-        # This method is required for `io` module compatibility.
         temp = self.read(len(b))
         if len(temp) == 0:
             return 0
@@ -736,17 +538,9 @@
             return len(temp)
 
     def supports_chunked_reads(self):
-        """
-        Checks if the underlying file-like object looks like a
-        :class:`http.client.HTTPResponse` object. We do this by testing for
-        the fp attribute. If it is present we assume it returns raw chunks as
-        processed by read_chunked().
-        """
         return hasattr(self._fp, "fp")
 
     def _update_chunk_length(self):
-        # First, we'll figure out length of a chunk and then
-        # we'll try to read it from socket.
         if self.chunk_left is not None:
             return
         line = self._fp.fp.readline()
@@ -754,7 +548,6 @@
         try:
             self.chunk_left = int(line, 16)
         except ValueError:
-            # Invalid chunked protocol response, abort.
             self.close()
             raise InvalidChunkLength(self, line)
 
@@ -763,7 +556,7 @@
         if amt is None:
             chunk = self._fp._safe_read(self.chunk_left)
             returned_chunk = chunk
-            self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
+            self._fp._safe_read(2)
             self.chunk_left = None
         elif amt < self.chunk_left:
             value = self._fp._safe_read(amt)
@@ -771,31 +564,17 @@
             returned_chunk = value
         elif amt == self.chunk_left:
             value = self._fp._safe_read(amt)
-            self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
+            self._fp._safe_read(2)
             self.chunk_left = None
             returned_chunk = value
-        else:  # amt > self.chunk_left
+        else:
             returned_chunk = self._fp._safe_read(self.chunk_left)
-            self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
+            self._fp._safe_read(2)
             self.chunk_left = None
         return returned_chunk
 
     def read_chunked(self, amt=None, decode_content=None):
-        """
-        Similar to :meth:`HTTPResponse.read`, but with an additional
-        parameter: ``decode_content``.
-
-        :param amt:
-            How much of the content to read. If specified, caching is skipped
-            because it doesn't make sense to cache partial content as the full
-            response.
-
-        :param decode_content:
-            If True, will attempt to decode the body based on the
-            'content-encoding' header.
-        """
         self._init_decoder()
-        # FIXME: Rewrite this method and make it a class with a better structured logic.
         if not self.chunked:
             raise ResponseNotChunked(
                 "Response is not chunked. "
@@ -808,13 +587,10 @@
             )
 
         with self._error_catcher():
-            # Don't bother reading the body of a HEAD request.
             if self._original_response and is_response_to_head(self._original_response):
                 self._original_response.close()
                 return
 
-            # If a response is already read and closed
-            # then return immediately.
             if self._fp.fp is None:
                 return
 
@@ -830,32 +606,21 @@
                     yield decoded
 
             if decode_content:
-                # On CPython and PyPy, we should never need to flush the
-                # decoder. However, on Jython we *might* need to, so
-                # lets defensively do it anyway.
                 decoded = self._flush_decoder()
-                if decoded:  # Platform-specific: Jython.
+                if decoded:
                     yield decoded
 
-            # Chunk content ends with \r\n: discard it.
             while True:
                 line = self._fp.fp.readline()
                 if not line:
-                    # Some sites may not end with '\r\n'.
                     break
                 if line == b"\r\n":
                     break
 
-            # We read everything; close the "file".
             if self._original_response:
                 self._original_response.close()
 
     def geturl(self):
-        """
-        Returns the URL that was the source of this response.
-        If the request that generated this response redirected, this method
-        will return the final redirect location.
-        """
         if self.retries is not None and len(self.retries.history):
             return self.retries.history[-1].redirect_location
         else:
@@ -876,4 +641,4 @@
             else:
                 buffer.append(chunk)
         if buffer:
-            yield b"".join(buffer)
+            yield b"".join(buffer)
